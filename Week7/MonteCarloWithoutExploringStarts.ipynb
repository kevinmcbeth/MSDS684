{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards:\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10| 1.00|\n",
      "---------------------------\n",
      "-0.10| 0.00|-0.10|-1.00|\n",
      "---------------------------\n",
      "-0.10|-0.10|-0.10|-0.10|\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2671f95fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final values:\n",
      "---------------------------\n",
      " 0.58| 0.78| 1.00| 0.00|\n",
      "---------------------------\n",
      " 0.41| 0.00| 0.77| 0.00|\n",
      "---------------------------\n",
      " 0.25| 0.11| 0.05| 0.00|\n",
      "final policy:\n",
      "---------------------------\n",
      "  R  |  R  |  R  |     |\n",
      "---------------------------\n",
      "  U  |     |  U  |     |\n",
      "---------------------------\n",
      "  U  |  L  |  L  |  D  |\n"
     ]
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/artificial-intelligence-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/artificial-intelligence-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "# sudo pip install -U future\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "from iterative_policy_evaluation import print_values, print_policy\n",
    "from monte_carlo_es import max_dict\n",
    "\n",
    "GAMMA = 0.9\n",
    "ALL_POSSIBLE_ACTIONS = ('U', 'D', 'L', 'R')\n",
    "\n",
    "# NOTE: find optimal policy and value function\n",
    "#       using on-policy first-visit MC\n",
    "\n",
    "def random_action(a, eps=0.1):\n",
    "  # choose given a with probability 1 - eps + eps/4\n",
    "  # choose some other a' != a with probability eps/4\n",
    "  p = np.random.random()\n",
    "  # if p < (1 - eps + eps/len(ALL_POSSIBLE_ACTIONS)):\n",
    "  #   return a\n",
    "  # else:\n",
    "  #   tmp = list(ALL_POSSIBLE_ACTIONS)\n",
    "  #   tmp.remove(a)\n",
    "  #   return np.random.choice(tmp)\n",
    "  #\n",
    "  # this is equivalent to the above\n",
    "  if p < (1 - eps):\n",
    "    return a\n",
    "  else:\n",
    "    return np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "def play_game(grid, policy):\n",
    "  # returns a list of states and corresponding returns\n",
    "  # in this version we will NOT use \"exploring starts\" method\n",
    "  # instead we will explore using an epsilon-soft policy\n",
    "  s = (2, 0)\n",
    "  grid.set_state(s)\n",
    "  a = random_action(policy[s])\n",
    "\n",
    "  # be aware of the timing\n",
    "  # each triple is s(t), a(t), r(t)\n",
    "  # but r(t) results from taking action a(t-1) from s(t-1) and landing in s(t)\n",
    "  states_actions_rewards = [(s, a, 0)]\n",
    "  while True:\n",
    "    r = grid.move(a)\n",
    "    s = grid.current_state()\n",
    "    if grid.game_over():\n",
    "      states_actions_rewards.append((s, None, r))\n",
    "      break\n",
    "    else:\n",
    "      a = random_action(policy[s]) # the next state is stochastic\n",
    "      states_actions_rewards.append((s, a, r))\n",
    "\n",
    "  # calculate the returns by working backwards from the terminal state\n",
    "  G = 0\n",
    "  states_actions_returns = []\n",
    "  first = True\n",
    "  for s, a, r in reversed(states_actions_rewards):\n",
    "    # the value of the terminal state is 0 by definition\n",
    "    # we should ignore the first state we encounter\n",
    "    # and ignore the last G, which is meaningless since it doesn't correspond to any move\n",
    "    if first:\n",
    "      first = False\n",
    "    else:\n",
    "      states_actions_returns.append((s, a, G))\n",
    "    G = r + GAMMA*G\n",
    "  states_actions_returns.reverse() # we want it to be in order of state visited\n",
    "  return states_actions_returns\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # use the standard grid again (0 for every step) so that we can compare\n",
    "  # to iterative policy evaluation\n",
    "  # grid = standard_grid()\n",
    "  # try the negative grid too, to see if agent will learn to go past the \"bad spot\"\n",
    "  # in order to minimize number of steps\n",
    "  grid = negative_grid(step_cost=-0.1)\n",
    "\n",
    "  # print rewards\n",
    "  print(\"rewards:\")\n",
    "  print_values(grid.rewards, grid)\n",
    "\n",
    "  # state -> action\n",
    "  # initialize a random policy\n",
    "  policy = {}\n",
    "  for s in grid.actions.keys():\n",
    "    policy[s] = np.random.choice(ALL_POSSIBLE_ACTIONS)\n",
    "\n",
    "  # initialize Q(s,a) and returns\n",
    "  Q = {}\n",
    "  returns = {} # dictionary of state -> list of returns we've received\n",
    "  states = grid.all_states()\n",
    "  for s in states:\n",
    "    if s in grid.actions: # not a terminal state\n",
    "      Q[s] = {}\n",
    "      for a in ALL_POSSIBLE_ACTIONS:\n",
    "        Q[s][a] = 0\n",
    "        returns[(s,a)] = []\n",
    "    else:\n",
    "      # terminal state or state we can't otherwise get to\n",
    "      pass\n",
    "\n",
    "  # repeat until convergence\n",
    "  deltas = []\n",
    "  for t in range(10000):\n",
    "    if t % 1000 == 0:\n",
    "      print(t)\n",
    "\n",
    "    # generate an episode using pi\n",
    "    biggest_change = 0\n",
    "    states_actions_returns = play_game(grid, policy)\n",
    "\n",
    "    # calculate Q(s,a)\n",
    "    seen_state_action_pairs = set()\n",
    "    for s, a, G in states_actions_returns:\n",
    "      # check if we have already seen s\n",
    "      # called \"first-visit\" MC policy evaluation\n",
    "      sa = (s, a)\n",
    "      if sa not in seen_state_action_pairs:\n",
    "        old_q = Q[s][a]\n",
    "        returns[sa].append(G)\n",
    "        Q[s][a] = np.mean(returns[sa])\n",
    "        biggest_change = max(biggest_change, np.abs(old_q - Q[s][a]))\n",
    "        seen_state_action_pairs.add(sa)\n",
    "    deltas.append(biggest_change)\n",
    "\n",
    "    # calculate new policy pi(s) = argmax[a]{ Q(s,a) }\n",
    "    for s in policy.keys():\n",
    "      a, _ = max_dict(Q[s])\n",
    "      policy[s] = a\n",
    "\n",
    "  plt.plot(deltas)\n",
    "  plt.show()\n",
    "\n",
    "  # find the optimal state-value function\n",
    "  # V(s) = max[a]{ Q(s,a) }\n",
    "  V = {}\n",
    "  for s in policy.keys():\n",
    "    V[s] = max_dict(Q[s])[1]\n",
    "\n",
    "  print(\"final values:\")\n",
    "  print_values(V, grid)\n",
    "  print(\"final policy:\")\n",
    "  print_policy(policy, grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
